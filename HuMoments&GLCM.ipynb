{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imágenes de entrenamiento procesadas: 10901\n",
      "Total de imágenes de test procesadas: 2698\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # Para la visualización de la matriz de confusión\n",
    "\n",
    "# Definir las carpetas de frutas frescas y podridas\n",
    "freshfruits = {\n",
    "    \"freshapples\": \"freshapple\",\n",
    "    \"freshbanana\": \"freshbanana\",\n",
    "    \"freshoranges\": \"freshorange\"\n",
    "}\n",
    "\n",
    "rottenfruits = {\n",
    "    \"rottenapples\": \"rottenapple\",\n",
    "    \"rottenbanana\": \"rottenbanana\",\n",
    "    \"rottenoranges\": \"rottenorange\"\n",
    "}\n",
    "\n",
    "# Inicializar listas para almacenar características y etiquetas\n",
    "data_train = []\n",
    "labels_train = []\n",
    "data_test = []\n",
    "labels_test = []\n",
    "\n",
    "# Función para extraer Hu Moments\n",
    "def extract_hu_moments(binary_img):\n",
    "    moments = cv2.moments(binary_img)\n",
    "    hu_moments = cv2.HuMoments(moments).flatten()\n",
    "    # Log-transform para normalizar los valores\n",
    "    hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-10)\n",
    "    return hu_moments\n",
    "\n",
    "# Función para extraer características GLCM\n",
    "def extract_glcm_features(gray_img):\n",
    "    # Definir distancias y ángulos para GLCM\n",
    "    distances = [1]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    glcm = graycomatrix(gray_img, distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "    \n",
    "    # Extraer propiedades de la GLCM\n",
    "    contrast = graycoprops(glcm, 'contrast').flatten()\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity').flatten()\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity').flatten()\n",
    "    energy = graycoprops(glcm, 'energy').flatten()\n",
    "    correlation = graycoprops(glcm, 'correlation').flatten()\n",
    "    \n",
    "    # Concatenar todas las propiedades en un solo vector\n",
    "    glcm_features = np.concatenate([contrast, dissimilarity, homogeneity, energy, correlation])\n",
    "    return glcm_features\n",
    "\n",
    "# Función para procesar imágenes y extraer características Hu Moments y GLCM\n",
    "def process_images(folder_dict, base_path, data_list, labels_list):\n",
    "    for folder, label in folder_dict.items():\n",
    "        folder_path = f\"{base_path}/{folder}/*.png\"\n",
    "        for image_path in glob.glob(folder_path):\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None or len(img.shape) != 3 or img.shape[2] != 3:\n",
    "                print(f\"Imagen no válida o con canales incorrectos: {image_path}\")\n",
    "                continue\n",
    "            try:\n",
    "                # Redimensionar la imagen\n",
    "                resized_img = cv2.resize(img, (64, 32))\n",
    "                \n",
    "                # Conversión a escala de grises\n",
    "                gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Binarización de la imagen para Hu Moments\n",
    "                _, binary_img = cv2.threshold(gray_img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "                \n",
    "                # Extracción de Hu Moments\n",
    "                hu_moments = extract_hu_moments(binary_img)\n",
    "                \n",
    "                # Extracción de características GLCM\n",
    "                glcm_features = extract_glcm_features(gray_img)\n",
    "                \n",
    "                # Concatenar Hu Moments y GLCM\n",
    "                features = np.concatenate([hu_moments, glcm_features])\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando {image_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Agregar las características y la etiqueta a las listas\n",
    "            data_list.append(features)\n",
    "            labels_list.append(label)\n",
    "\n",
    "# Procesar imágenes de entrenamiento\n",
    "train_base_path = \".gitignore/dataset/train\"\n",
    "process_images(freshfruits, train_base_path, data_train, labels_train)\n",
    "process_images(rottenfruits, train_base_path, data_train, labels_train)\n",
    "\n",
    "print(\"Total de imágenes de entrenamiento procesadas:\", len(data_train))\n",
    "\n",
    "# Procesar imágenes de prueba\n",
    "test_base_path = \".gitignore/dataset/test\"\n",
    "process_images(freshfruits, test_base_path, data_test, labels_test)\n",
    "process_images(rottenfruits, test_base_path, data_test, labels_test)\n",
    "\n",
    "print(\"Total de imágenes de test procesadas:\", len(data_test))\n",
    "\n",
    "# Convertir las características y etiquetas a arrays de NumPy\n",
    "X_train = np.array(data_train)\n",
    "y_train_labels = np.array(labels_train)\n",
    "X_test = np.array(data_test)\n",
    "y_test_labels = np.array(labels_test)\n",
    "\n",
    "# Codificar las etiquetas de forma consistente\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(np.concatenate((y_train_labels, y_test_labels)))\n",
    "\n",
    "y_train = encoder.transform(y_train_labels)\n",
    "y_test = encoder.transform(y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- SVM amb Kernel Polinòmic -----\n",
      "Accuracy: 0.3462\n",
      "\n",
      "Informe de classificació:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  freshapple       0.36      0.12      0.18       395\n",
      " freshbanana       0.41      0.38      0.40       381\n",
      " freshorange       0.35      0.02      0.04       388\n",
      " rottenapple       0.28      0.86      0.42       601\n",
      "rottenbanana       0.69      0.39      0.50       530\n",
      "rottenorange       0.44      0.02      0.03       403\n",
      "\n",
      "    accuracy                           0.35      2698\n",
      "   macro avg       0.42      0.30      0.26      2698\n",
      "weighted avg       0.42      0.35      0.29      2698\n",
      "\n",
      "Matriu de Confusió:\n",
      "[[ 48  36   6 290  15   0]\n",
      " [ 15 145   2 188  26   5]\n",
      " [  7  71   9 294   6   1]\n",
      " [ 22  29   0 517  33   0]\n",
      " [ 33  25   0 261 208   3]\n",
      " [  8  47   9 318  14   7]]\n"
     ]
    }
   ],
   "source": [
    "# SVM amb Kernel Polinòmic - Model de Classificació\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir i entrenar el model SVM amb kernel polinòmic\n",
    "poly_classifier = SVC(kernel='poly', degree=3, coef0=1, probability=True, random_state=42)\n",
    "poly_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predir sobre el conjunt de prova\n",
    "y_pred_poly = poly_classifier.predict(X_test)\n",
    "\n",
    "# Avaluar el model\n",
    "accuracy_poly = accuracy_score(y_test, y_pred_poly)\n",
    "print(\"----- SVM amb Kernel Polinòmic -----\")\n",
    "print(f\"Accuracy: {accuracy_poly:.4f}\\n\")\n",
    "print(\"Informe de classificació:\")\n",
    "print(classification_report(y_test, y_pred_poly, target_names=encoder.classes_))\n",
    "print(\"Matriu de Confusió:\")\n",
    "print(confusion_matrix(y_test, y_pred_poly))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
