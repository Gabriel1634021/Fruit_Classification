{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!pip install opencv-python\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#!pip install scikit-image\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m color, feature\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hog\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imread\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python\n",
    "#!pip install scikit-image\n",
    "\n",
    "from skimage import color, feature\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "import os\n",
    "import glob\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color, feature\n",
    "print(\"Scikit-image se ha importado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Anàlisi del atributs**\n",
    "\n",
    "### **Càrrega i visualització d'una imatge**\n",
    "Primer, carreguem una imatge del dataset utilitzant la funció `mpimg.imread`, que converteix la imatge en un array de NumPy per poder treballar-hi. Aquesta imatge pertany a la carpeta de \"freshapples\". Un cop carregada, habilitem l'opció d'escriure sobre l'array amb `setflags(write=1)` per permetre modificacions en el futur.\n",
    "\n",
    "Després, imprimim les dimensions de la imatge (`img.shape`) per confirmar la seva resolució i nombre de canals (normalment 3 si és en color). Finalment, visualitzem la imatge amb `plt.imshow()` per assegurar-nos que es veu correctament i per familiaritzar-nos amb les dades abans de començar el processament.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img=np.array(mpimg.imread('.gitignore/dataset/train/freshapples/rotated_by_15_Screen Shot 2018-06-08 at 4.59.36 PM.png'))\n",
    "img.setflags(write=1)\n",
    "print('Image : ',img.shape)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Redimensionament i visualització d'una imatge**\n",
    "Redimensionem la imatge carregada prèviament utilitzant la funció `cv2.resize`. Ajustem les seves dimensions a 150x150 píxels per reduir la mida de les dades i optimitzar el processament.\n",
    "\n",
    "Després del redimensionament, mostrem la imatge redimensionada amb `plt.imshow()` per verificar que s'ha aplicat correctament. Finalment, utilitzem `print(resized_img.shape)` per comprovar que les dimensions resultants són les esperades (150x150 píxels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Redimensionar la imatge\n",
    "resized_img = cv2.resize(img, (150, 150))\n",
    "\n",
    "# Mostrar la imatge redimensionada\n",
    "plt.imshow(resized_img)\n",
    "plt.show()\n",
    "print(resized_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracció de característiques amb HOG**\n",
    "A continuació, convertim la imatge a RGB seleccionant només aquests canals i eliminem l'eventual canal alfa de la imatge (`resized_img[:, :, :3]`).\n",
    "\n",
    "Després, convertim la imatge a una escala de grisos utilitzant la funció `color.rgb2gray`, eliminant la complexitat dels colors per centrar-nos en l'estructura i els detalls importants.\n",
    "\n",
    "Posteriorment, calculem les característiques HOG (Histogram of Oriented Gradients) amb la funció `feature.hog`. Aquesta tècnica ens permet detectar formes i textures a partir dels gradients de la imatge. També activem l'opció de visualització (`visualize=True`) per obtenir una representació visual del HOG.\n",
    "\n",
    "Finalment, imprimim les dimensions i els valors de les característiques HOG (`fd`) i mostrem la imatge HOG amb `plt.imshow`, utilitzant un mapa de color en escala de grisos (`cmap=\"gray\"`).\n",
    "\n",
    "```python\n",
    "print(fd.shape)       # Mostrem la forma de les característiques HOG\n",
    "print(fd)             # Mostrem les característiques HOG\n",
    "print(hog_image.shape)  # Mostrem la forma de la imatge HOG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color, feature\n",
    "# Remove the alpha channel from the image\n",
    "rgb_img = resized_img[:, :, :3]\n",
    "\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_img = color.rgb2gray(rgb_img)\n",
    "\n",
    "# Compute HOG features for the grayscale image\n",
    "fd, hog_image = feature.hog(gray_img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                            cells_per_block=(2, 2), visualize=True)\n",
    "\n",
    "print(fd.shape)\n",
    "print(fd)\n",
    "print(hog_image.shape)\n",
    "# Display the HOG image\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(hog_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Processament i anàlisi del dataset**\n",
    "\n",
    "En aquest codi processem el dataset de fruites (fresques i podrides), extraient característiques amb HOG i preparant les dades per a la classificació.\n",
    "\n",
    "#### **Processament del dataset**\n",
    "1. Carreguem les imatges de les carpetes corresponents (`freshapples`, `rottenapples`, etc.).\n",
    "2. Preprocessem cada imatge:\n",
    "   - Redimensionem a 150x150 píxels.\n",
    "   - Convertim a escala de grisos.\n",
    "   - Extraiem característiques HOG per identificar patrons visuals (bordes i textures).\n",
    "3. Guardem les característiques a `data` i les etiquetes a `labels`, comptant les imatges per categoria.\n",
    "\n",
    "#### **Visualització**\n",
    "Generem un gràfic de barres per mostrar la distribució d’imatges per categoria i verificar que el dataset està equilibrat.\n",
    "\n",
    "```python\n",
    "plt.bar(fruit_labels, image_counts, color=['green', 'yellow', 'orange', 'red', 'purple', 'brown'])\n",
    "plt.title('Distribució de les Imatges')\n",
    "plt.xlabel('Tipus de Fruita')\n",
    "plt.ylabel('Número d’Imatges')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Inicializar listas globales para características y etiquetas\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Definir rutas y etiquetas correspondientes\n",
    "freshfruits = {\n",
    "    \"freshapples\": \"freshapple\",\n",
    "    \"freshbanana\": \"freshbanana\",\n",
    "    \"freshoranges\": \"freshorange\"\n",
    "}\n",
    "\n",
    "rottenfruits = {\n",
    "    \"rottenapples\": \"rottenapple\",\n",
    "    \"rottenbanana\": \"rottenbanana\",\n",
    "    \"rottenoranges\": \"rottenorange\"\n",
    "}\n",
    "\n",
    "# Inicializar contadores para cada categoría\n",
    "fruit_counts = {\n",
    "    \"freshapple\": 0,\n",
    "    \"freshbanana\": 0,\n",
    "    \"freshorange\": 0,\n",
    "    \"rottenapple\": 0,\n",
    "    \"rottenbanana\": 0,\n",
    "    \"rottenorange\": 0\n",
    "}\n",
    "\n",
    "# Procesar cada tipo de fruta frescas\n",
    "for fruit_folder, label in freshfruits.items():\n",
    "    folder_path = f\".gitignore/dataset/train/{fruit_folder}/*.png\"\n",
    "    for entry in glob.glob(folder_path):\n",
    "        img = cv2.imread(entry)  # Leer imagen\n",
    "        resized_img = cv2.resize(img, (150, 150))  # Redimensionar imagen\n",
    "        gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)  # Convertir a escala de grises\n",
    "        fd = hog(gray_img)  # Calcular características HOG\n",
    "        data.append(fd)  # Agregar características\n",
    "        labels.append(label)  # Agregar etiqueta correspondiente\n",
    "        fruit_counts[label] += 1  # Contar imagen por etiqueta\n",
    "    print(f\"{label.capitalize()} Images: {fruit_counts[label]}\")\n",
    "\n",
    "# Procesar cada tipo de fruta no frescas\n",
    "for fruit_folder, label in rottenfruits.items():\n",
    "    folder_path = f\".gitignore/dataset/train/{fruit_folder}/*.png\"\n",
    "    for entry in glob.glob(folder_path):\n",
    "        img = cv2.imread(entry)  # Leer imagen\n",
    "        resized_img = cv2.resize(img, (150, 150))  # Redimensionar imagen\n",
    "        gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)  # Convertir a escala de grises\n",
    "        fd = hog(gray_img)  # Calcular características HOG\n",
    "        data.append(fd)  # Agregar características\n",
    "        labels.append(label)  # Agregar etiqueta correspondiente\n",
    "        fruit_counts[label] += 1  # Contar imagen por etiqueta\n",
    "    print(f\"{label.capitalize()} Images: {fruit_counts[label]}\")\n",
    "\n",
    "# Verificar la longitud de los datos y las etiquetas\n",
    "print(\"Total number of images: \" + str(len(data)))\n",
    "print(\"Total number of labels: \" + str(len(labels)))\n",
    "\n",
    "# Datos para el gráfico\n",
    "fruit_labels = list(fruit_counts.keys())\n",
    "image_counts = list(fruit_counts.values())\n",
    "\n",
    "# Crear gráfico de barras\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(fruit_labels, image_counts, color=['green', 'yellow', 'orange', 'red', 'purple', 'brown'])\n",
    "\n",
    "# Añadir títulos y etiquetas\n",
    "plt.title('Distribución de Imágenes de Frutas (Frescas y Podridas)', fontsize=14)\n",
    "plt.xlabel('Tipo de Fruta', fontsize=12)\n",
    "plt.ylabel('Número de Imágenes', fontsize=12)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Ajusta el diseño para que las etiquetas no se solapen\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Entrenament i avaluació del model**\n",
    "\n",
    "Aquest codi entrena un model SVM amb l’estratègia One-vs-One per classificar el tipus de fruita (`apple`, `banana`, `orange`), independentment de si està fresca o podrida.\n",
    "\n",
    "#### **Procés**\n",
    "1. Convertim les dades i etiquetes a arrays de NumPy i normalitzem les etiquetes per identificar només el tipus de fruita.\n",
    "2. Codifiquem les etiquetes amb `LabelEncoder` i dividim les dades en entrenament (70%) i prova (30%) amb estratificació.\n",
    "3. Configurem i entrenem el model SVM amb kernel lineal.\n",
    "4. Avaluem el model amb l'exactitud (`accuracy_score`) i un informe de classificació (`classification_report`).\n",
    "\n",
    "#### **Objectiu**\n",
    "Identificar el tipus de fruita amb alta precisió i verificar el rendiment amb les dades de prova.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Convertir los datos y etiquetas a arrays\n",
    "data = np.array(data)\n",
    "\n",
    "# Suponiendo que ya tienes las listas `freshfruits` y `rottenfruits`\n",
    "# Crear las etiquetas originales a partir de las carpetas de frutas frescas y podridas\n",
    "original_labels = []\n",
    "\n",
    "# Etiquetas de frutas frescas\n",
    "for fruit_folder, label in freshfruits.items():\n",
    "    folder_path = f\".gitignore/dataset/train/{fruit_folder}/*.png\"\n",
    "    for entry in glob.glob(folder_path):\n",
    "        original_labels.append(label)\n",
    "\n",
    "# Etiquetas de frutas podridas\n",
    "for fruit_folder, label in rottenfruits.items():\n",
    "    folder_path = f\".gitignore/dataset/train/{fruit_folder}/*.png\"\n",
    "    for entry in glob.glob(folder_path):\n",
    "        original_labels.append(label)\n",
    "\n",
    "# Normalizar las etiquetas para que sean solo tipos de frutas (ignorando si están frescas o podridas)\n",
    "def normalize_label(label):\n",
    "    if \"apple\" in label:\n",
    "        return \"apple\"\n",
    "    elif \"banana\" in label:\n",
    "        return \"banana\"\n",
    "    elif \"orange\" in label:\n",
    "        return \"orange\"\n",
    "    return label  # En caso de que no coincida con las opciones anteriores\n",
    "\n",
    "# Normalizar las etiquetas antes de codificarlas\n",
    "normalized_labels = np.array([normalize_label(label) for label in original_labels])\n",
    "\n",
    "# Codificar etiquetas como valores numéricos\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(normalized_labels)\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, encoded_labels, test_size=0.3, random_state=42, stratify=encoded_labels)\n",
    "\n",
    "# Configurar el modelo con la estrategia One-vs-One\n",
    "ovo_classifier = OneVsOneClassifier(SVC(kernel='linear', probability=True, random_state=42))\n",
    "\n",
    "# Entrenar el modelo\n",
    "ovo_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = ovo_classifier.predict(X_test)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Entrenament i avaluació del model**\n",
    "\n",
    "Utilitzem un model SVM amb estratègia One-vs-Rest per classificar el tipus de fruita (`apple`, `banana`, `orange`).\n",
    "\n",
    "#### **Procés**\n",
    "1. Normalitzem i codifiquem les etiquetes per identificar només el tipus de fruita.\n",
    "2. Dividim les dades en entrenament (70%) i prova (30%).\n",
    "3. Entrenem un model SVM amb kernel lineal.\n",
    "4. Avaluem l'exactitud i generem un informe de classificació.\n",
    "\n",
    "#### **Objectiu**\n",
    "Comparar el rendiment del model amb l'estratègia One-vs-One.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Convertir los datos y etiquetas a arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "original_labels = []\n",
    "for fruit_folder, label in freshfruits.items():\n",
    "    folder_path = f\".gitignore/dataset/train/{fruit_folder}/*.png\"\n",
    "    for entry in glob.glob(folder_path):\n",
    "        original_labels.append(label)\n",
    "\n",
    "for fruit_folder, label in rottenfruits.items():\n",
    "    folder_path = f\".gitignore/dataset/train/{fruit_folder}/*.png\"\n",
    "    for entry in glob.glob(folder_path):\n",
    "        original_labels.append(label)\n",
    "\n",
    "# Normalizar las etiquetas para que sean solo tipos de frutas (ignorando si están frescas o podridas)\n",
    "def normalize_label(label):\n",
    "    if \"apple\" in label:\n",
    "        return \"apple\"\n",
    "    elif \"banana\" in label:\n",
    "        return \"banana\"\n",
    "    elif \"orange\" in label:\n",
    "        return \"orange\"\n",
    "\n",
    "# Normalizar las etiquetas antes de codificarlas\n",
    "normalized_labels = np.array([normalize_label(label) for label in original_labels])\n",
    "\n",
    "# Codificar etiquetas como valores numéricos\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(normalized_labels)\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, encoded_labels, test_size=0.3, random_state=42, stratify=encoded_labels)\n",
    "\n",
    "# Configurar el modelo con la estrategia One-vs-Rest\n",
    "ovr_classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=42))\n",
    "\n",
    "# Entrenar el modelo\n",
    "ovr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = ovr_classifier.predict(X_test)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Anàlisi dels resultats**\n",
    "\n",
    "Els resultats de l’estratègia One-vs-Rest són similars als de l’estratègia One-vs-One. Per aprofundir en l’anàlisi, provarem diferents tipus de kernel en el model SVM per observar com varien els resultats i determinar si algun kernel ofereix una millora significativ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classificació amb Kernel RBF**\n",
    "\n",
    "Provem un model SVM amb kernel RBF (`Radial Basis Function`) per veure com afecta la no linealitat als resultats de classificació.\n",
    "\n",
    "#### **Característiques rellevants**\n",
    "- **Gamma:** Configurat a `scale`, ajusta automàticament la influència dels punts de dades individuals.\n",
    "- **Adaptació a no linealitats:** El kernel RBF permet capturar relacions més complexes en les dades.\n",
    "\n",
    "#### **Objectiu**\n",
    "Analitzar si el kernel RBF millora el rendiment respecte al kernel lineal utilitzat anteriorment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, encoded_labels, test_size=0.3, random_state=42, stratify=encoded_labels)\n",
    "\n",
    "# Configurar el modelo con el kernel RBF\n",
    "rbf_classifier = SVC(kernel='rbf', gamma='scale', probability=True, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "rbf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = rbf_classifier.predict(X_test)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classificació amb Kernel Polinòmic**\n",
    "\n",
    "Provem un model SVM amb kernel polinòmic per avaluar com afecta aquest tipus de kernel als resultats de classificació.\n",
    "\n",
    "#### **Característiques rellevants**\n",
    "- **Degree:** Configurat a 3, defineix el grau del polinomi i la complexitat de les relacions que pot modelar.\n",
    "- **Coef0:** Configurat a 1, controla l’impacte dels termes independents del polinomi.\n",
    "- **Aplicació:** Ideal per capturar relacions moderadament no lineals en les dades.\n",
    "\n",
    "#### **Objectiu**\n",
    "Determinar si el kernel polinòmic, amb un grau fixat a 3, ofereix una millora respecte al kernel lineal i RBF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el modelo con el kernel polinómico\n",
    "poly_classifier = SVC(kernel='poly', degree=3, coef0=1, probability=True, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "poly_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = poly_classifier.predict(X_test)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provem amb models preentrenats:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classificació amb Transfer Learning utilitzant VGG16**\n",
    "\n",
    "En aquest codi, implementem un model de classificació de fruites utilitzant transfer learning amb l’arquitectura preentrenada VGG16.\n",
    "\n",
    "#### **Característiques clau**\n",
    "- **VGG16 preentrenat:** S’utilitza com a base amb els pesos d’ImageNet, eliminant la capa superior (`include_top=False`) per adaptar-lo al nostre problema.\n",
    "- **Capacitat d'aprenentatge congelada:** Les capes de VGG16 es mantenen no entrenables (`layer.trainable = False`) per aprofitar les característiques preentrenades.\n",
    "- **Cap personalitzada:** S’afegeixen capes al final:\n",
    "  - `GlobalAveragePooling2D`: Per reduir la dimensionalitat.\n",
    "  - `Dense` amb 1024 unitats i activació `relu` per afegir complexitat.\n",
    "  - `Dense` amb 6 unitats i activació `softmax` per a la classificació de les 6 classes.\n",
    "\n",
    "#### **Generació de dades**\n",
    "- Utilitzem `ImageDataGenerator` per generar dades augmentades:\n",
    "  - Escalem els píxels a un rang [0, 1].\n",
    "  - Apliquem transformacions com rotacions, desplaçaments, zooms i reflexions horitzontals per evitar sobreajustament.\n",
    "- Les dades es carreguen en carpetes separades per a entrenament i validació.\n",
    "\n",
    "#### **Entrenament**\n",
    "- El model es compila amb `categorical_crossentropy` com a funció de pèrdua i `Adam` com a optimitzador.\n",
    "- Entrenem durant 10 èpoques utilitzant les dades augmentades.\n",
    "\n",
    "#### **Objectiu**\n",
    "Aprofitar el transfer learning amb VGG16 per millorar la classificació multiclasse de fruites i comparar els resultats amb els models SVM anteriors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Ruta a las carpetas de entrenamiento y validación\n",
    "train_dir = '.gitignore/dataset/train'\n",
    "test_dir = '.gitignore/dataset/test'\n",
    "\n",
    "# Usar VGG16 preentrenado sin la capa superior\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Congelar las capas del modelo base\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Añadir nuestras capas personalizadas\n",
    "x = vgg_base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(6, activation='softmax')(x)  # 6 clases en total: freshapple, freshbanana, freshorange, rottenapple, rottenbanana, rottenorange\n",
    "\n",
    "# Crear el modelo final\n",
    "model = Model(inputs=vgg_base.input, outputs=x)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Crear generadores de datos para entrenar y validar\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Escalar los píxeles a un rango [0, 1]\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Cargar las imágenes de entrenamiento\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # Ruta de entrenamiento\n",
    "    target_size=(224, 224),  # Tamaño para VGG16\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Como es clasificación multiclase\n",
    ")\n",
    "\n",
    "# Cargar las imágenes de validación\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    test_dir,  # Ruta de prueba\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save('fruit_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Avaluació del model amb dades de prova**\n",
    "\n",
    "En aquest codi, avaluem el model entrenat utilitzant el conjunt de dades de prova i generem mètriques per analitzar-ne el rendiment.\n",
    "\n",
    "#### **Característiques clau**\n",
    "- **Generador de dades de validació:** Es carrega el conjunt de prova amb `ImageDataGenerator` i es manté l'ordre de les etiquetes (`shuffle=False`) per garantir que les prediccions coincideixin amb les etiquetes reals.\n",
    "- **Prediccions:** Utilitzem el model carregat (`fruit_classification_model.h5`) per generar prediccions sobre el conjunt de prova.\n",
    "- **Mètriques d’avaluació:**\n",
    "  - **Informe de classificació (`classification_report`):** Mostra mètriques com precisió, recall i F1-score per cada classe.\n",
    "  - **Matriiu de confusió:** Identifica on es produeixen errors en les prediccions, visualitzant les etiquetes reals vs. prediccions.\n",
    "\n",
    "#### **Visualització**\n",
    "- La **matriz de confusió** es representa gràficament amb un mapa de calor (`heatmap`) que facilita identificar les classes amb millor i pitjor rendiment.\n",
    "\n",
    "#### **Objectiu**\n",
    "Avaluar la precisió i consistència del model en dades reals de prova i identificar possibles millores per optimitzar el rendiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Directorio de prueba\n",
    "test_dir = '.gitignore/dataset/test'\n",
    "\n",
    "# Crear generador de datos para validación\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Importante para mantener el orden de las etiquetas\n",
    ")\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = tf.keras.models.load_model('fruit_classification_model.h5')\n",
    "\n",
    "# Generar predicciones con el conjunto de validación\n",
    "validation_generator.reset()  # Reiniciar el generador\n",
    "predictions = model.predict(validation_generator, steps=validation_generator.samples // validation_generator.batch_size + 1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Obtener las etiquetas reales\n",
    "true_classes = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# Generar el informe de clasificación\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(report)\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.ylabel('Etiqueta Real')\n",
    "plt.xlabel('Etiqueta Predicha')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
